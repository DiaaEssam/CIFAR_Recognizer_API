{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-07-06T08:07:26.216429Z","iopub.execute_input":"2023-07-06T08:07:26.216932Z","iopub.status.idle":"2023-07-06T08:07:26.222565Z","shell.execute_reply.started":"2023-07-06T08:07:26.216893Z","shell.execute_reply":"2023-07-06T08:07:26.221390Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# preparing TPU","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T08:07:26.230464Z","iopub.execute_input":"2023-07-06T08:07:26.230800Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Running on TPU  \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:TPU system local has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:TPU system local has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Initializing the TPU system: local\nfree(): corrupted unsorted chunks\nhttps://symbolize.stripped_domain/r/?trace=7fbaee2e3ce1,7fbaee2e3d5f,7fbaee32c699,0&map= \n*** SIGABRT received by PID 15 (TID 1002) on cpu 16 from PID 15; stack trace: ***\nPC: @     0x7fbaee2e3ce1  (unknown)  raise\n    @     0x7fbaa6cc705a       1152  (unknown)\n    @     0x7fbaee2e3d60       4192  (unknown)\n    @     0x7fbaee32c69a  (unknown)  (unknown)\n    @                0x1  (unknown)  (unknown)\nhttps://symbolize.stripped_domain/r/?trace=7fbaee2e3ce1,7fbaa6cc7059,7fbaee2e3d5f,7fbaee32c699,0&map=1278088d049ad36cb636fbbc76303cb3:7fba9b691000-7fbaa6ede7c0 \nE0706 08:07:28.615046    1002 coredump_hook.cc:414] RAW: Remote crash data gathering hook invoked.\nE0706 08:07:28.615141    1002 client.cc:278] RAW: Coroner client retries enabled (b/136286901), will retry for up to 30 sec.\nE0706 08:07:28.615150    1002 coredump_hook.cc:512] RAW: Sending fingerprint to remote end.\nE0706 08:07:28.615157    1002 coredump_socket.cc:120] RAW: Stat failed errno=2 on socket /var/google/services/logmanagerd/remote_coredump.socket\nE0706 08:07:28.615162    1002 coredump_hook.cc:518] RAW: Cannot send fingerprint to Coroner: [NOT_FOUND] Missing crash reporting socket. Is the listener running?\nE0706 08:07:28.615166    1002 coredump_hook.cc:580] RAW: Dumping core locally.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.layers as tfl\nfrom keras import backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"cirxDGj9Eax8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar100\n\n(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='coarse')","metadata":{"id":"KUZ3kYfcEayD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,y_train.shape)","metadata":{"id":"WYrgmC3xEayE","outputId":"2f2b1991-8d89-4132-f44a-6c095d9f2084","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing images","metadata":{}},{"cell_type":"code","source":"import cv2\nX_train = np.array([cv2.resize(img, (140, 140)) for img in X_train])","metadata":{"id":"ts-FzgdVXpVL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.array([cv2.resize(img, (140, 140)) for img in X_test])","metadata":{"id":"ZLrsEjC1XpVM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding labels","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder()\ny_train=enc.fit_transform(y_train).toarray().astype(int)\ny_test=enc.transform(y_test).toarray().astype(int)\n\n\nprint(y_train.shape)\nprint(y_train[0])","metadata":{"id":"fe0R6KgtEayF","outputId":"921d3734-afcd-47c7-9252-43ed819197c9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building ResNet-50","metadata":{}},{"cell_type":"code","source":"def identity_block(X, f, filters):\n    X_shortcut=X\n\n    X=tfl.Conv2D(filters=filters[0],kernel_size=1,strides=(1,1), padding='valid')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n    X=tfl.Activation('relu')(X)\n\n    X=tfl.Conv2D(filters=filters[1],kernel_size=f,strides=(1,1), padding='same')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n    X=tfl.Activation('relu')(X)\n\n    X=tfl.Conv2D(filters=filters[2],kernel_size=1,strides=(1,1), padding='valid')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n\n    X=tfl.Add()([X_shortcut,X])\n    X=tfl.Activation('relu')(X)\n\n    return X","metadata":{"id":"4UTkCcT3EayJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convolutional_block(X, f, filters, s=2):\n    X_shortcut=X\n\n    X=tfl.Conv2D(filters=filters[0],kernel_size=1,strides=(s,s), padding='valid')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n    X=tfl.Activation('relu')(X)\n\n    X=tfl.Conv2D(filters=filters[1],kernel_size=f,strides=(1,1), padding='same')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n    X=tfl.Activation('relu')(X)\n\n    X=tfl.Conv2D(filters=filters[2],kernel_size=1,strides=(1,1), padding='valid')(X)\n    X=tfl.BatchNormalization(axis=3)(X, training=True)\n\n    X_shortcut=tfl.Conv2D(filters=filters[2],kernel_size=1,strides=(s,s), padding='valid')(X_shortcut)\n    X_shortcut=tfl.BatchNormalization(axis=3)(X_shortcut, training=True)\n\n    X=tfl.Add()([X_shortcut,X])\n    X=tfl.Activation('relu')(X)\n\n    return X","metadata":{"id":"w2IxMGMoEayK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def arch(input_shape):\n\n    input_img = tf.keras.Input(shape=input_shape)\n\n    #layer = data_augmenter()(input_img)\n\n    layer =tfl.ZeroPadding2D((3, 3))(input_img)\n\n    layer=tfl.Conv2D(filters=64,kernel_size=7,strides=(2,2))(layer)\n    layer=tfl.BatchNormalization(axis=3)(layer, training=True)\n    layer=tfl.Activation('relu')(layer)\n    layer=tfl.MaxPooling2D((3, 3), strides=(2, 2))(layer)\n\n    layer=convolutional_block(layer,3,[64,64,256],1)\n    layer=identity_block(layer,3,[64,64,256])\n    layer=identity_block(layer,3,[64,64,256])\n\n    layer=convolutional_block(layer,3,[128,128,512],2)\n    layer=identity_block(layer,3,[128,128,512])\n    layer=identity_block(layer,3,[128,128,512])\n    layer=identity_block(layer,3,[128,128,512])\n\n    layer=convolutional_block(layer,3, [256, 256, 1024],2)\n    layer=identity_block(layer,3, [256, 256, 1024])\n    layer=identity_block(layer,3, [256, 256, 1024])\n    layer=identity_block(layer,3, [256, 256, 1024])\n    layer=identity_block(layer,3, [256, 256, 1024])\n    layer=identity_block(layer,3, [256, 256, 1024])\n\n    layer=convolutional_block(layer,3, [512, 512, 2048],2)\n    layer=identity_block(layer,3, [512, 512, 2048])\n    layer=identity_block(layer,3, [512, 512, 2048])\n\n    layer=tfl.AveragePooling2D(pool_size=(2, 2),padding='same')(layer)\n    layer=tfl.Flatten()(layer)\n\n    outputs=tfl.Dense(units= 20 , activation='softmax')(layer)\n    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n    return model","metadata":{"id":"5OSWpYP_EayK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training and evaluating the model","metadata":{}},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\nwith strategy.scope():\n    conv_model = arch((140, 140, 3)) # define your model normally\n    conv_model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \nconv_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16 * strategy.num_replicas_in_sync)\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16 * strategy.num_replicas_in_sync)\nhistory = conv_model.fit(train_dataset,epochs=4,validation_data=test_dataset,batch_size=16 * strategy.num_replicas_in_sync,shuffle=True)","metadata":{"id":"UJVVZ58UEayL","outputId":"ad39198b-86c3-46ba-f9e8-128b818b0bf2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}